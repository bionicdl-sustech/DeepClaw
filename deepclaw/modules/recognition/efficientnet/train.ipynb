{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%reload_ext autoreload\n",
    "%autoreload 2\n",
    "%matplotlib inline\n",
    "import os\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"]=\"1\"\n",
    "\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from __future__ import print_function\n",
    "import keras\n",
    "from keras.models import load_model\n",
    "from keras.models import Sequential\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras.layers import Dense, Dropout, Activation, Flatten\n",
    "from keras.layers import Conv2D, MaxPooling2D, GlobalAveragePooling2D\n",
    "from keras.callbacks import TensorBoard\n",
    "from keras import applications\n",
    "from keras.models import Model, load_model\n",
    "import numpy as np\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "from keras_applications.efficientnet import preprocess_input\n",
    "\n",
    "from datetime import datetime\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data generators, data augmentation\n",
    "def preprocessing_f(x):\n",
    "    return preprocess_input(x, data_format=None, backend=keras.backend, layers=keras.layers, models=keras.models, utils=keras.utils)\n",
    "\n",
    "train = ImageDataGenerator(\n",
    "    rotation_range = 90.0,\n",
    "    width_shift_range=0.2,\n",
    "    height_shift_range=0.2,\n",
    "    horizontal_flip = True,\n",
    "    vertical_flip = True,\n",
    "    fill_mode = 'nearest',\n",
    "    preprocessing_function = preprocessing_f)\n",
    "\n",
    "valid = ImageDataGenerator(\n",
    "    fill_mode = 'nearest',\n",
    "    preprocessing_function = preprocessing_f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 12709 images belonging to 4 classes.\n",
      "Found 1413 images belonging to 4 classes.\n"
     ]
    }
   ],
   "source": [
    "# Target directories \n",
    "batch_size = 32\n",
    "img_size = 300\n",
    "\n",
    "trainGenerator = train.flow_from_directory('/raid/wanfang/Documents/simple_recyclable_classification/train', target_size = (img_size, img_size), batch_size=batch_size,\n",
    "    class_mode = \"categorical\", color_mode = \"rgb\", shuffle=True, seed=42)\n",
    "\n",
    "validationGenerator = valid.flow_from_directory('/raid/wanfang/Documents/simple_recyclable_classification/test', target_size = (img_size, img_size), batch_size=batch_size,\n",
    "    class_mode = \"categorical\", color_mode = \"rgb\", shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow_core/python/ops/resource_variable_ops.py:1630: calling BaseResourceVariable.__init__ (from tensorflow.python.ops.resource_variable_ops) with constraint is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "If using Keras pass *_constraint arguments to layers.\n"
     ]
    }
   ],
   "source": [
    "# Neural network\n",
    "from keras_applications.efficientnet import EfficientNetB3\n",
    "\n",
    "base_model = EfficientNetB3(include_top=False,\n",
    "                   weights='imagenet',\n",
    "                   input_tensor=None,\n",
    "                   input_shape=(img_size, img_size, 3),\n",
    "                   pooling=None,\n",
    "                   backend=keras.backend, layers=keras.layers, models=keras.models, utils=keras.utils)\n",
    "\n",
    "# add a global spatial average pooling layer\n",
    "x = base_model.output\n",
    "x = GlobalAveragePooling2D()(x)\n",
    "# let's add a fully-connected layer\n",
    "x = Dense(1024, activation='relu')(x)\n",
    "# and a logistic layer -- let's say we have 200 classes\n",
    "predictions = Dense(4, activation='softmax')(x)\n",
    "# this is the model we will train\n",
    "model = Model(inputs=base_model.input, outputs=predictions)\n",
    "\n",
    "# x = Flatten()(base.output)\n",
    "# x = Dropout(0.5)(x)\n",
    "# x = Dense(4, activation='softmax')(x)\n",
    "# model = Model(inputs=base.inputs, outputs=x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set optimizer and loss function\n",
    "opt_adam = keras.optimizers.Adam(lr=0.0001, amsgrad=True)\n",
    "model.compile(loss='categorical_crossentropy',\n",
    "            optimizer=opt_adam,\n",
    "            metrics=['categorical_accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# callbacks\n",
    "tensorboard = TensorBoard(log_dir=\"logs/Recyclable-{}-EfficientNetB3-bs32\".format(datetime.now().isoformat()[:19]))\n",
    "reduce_lr = keras.callbacks.ReduceLROnPlateau(monitor='val_categorical_accuracy', factor=0.1, patience=5, min_lr=0.00000001, min_delta=1e-2)\n",
    "checkpoint = keras.callbacks.ModelCheckpoint('logs/Recyclable-bs32-weights.{epoch:02d}-{val_categorical_accuracy:.3f}-DenseNet169.hdf5', monitor='val_categorical_accuracy', \n",
    "        verbose=1, save_best_only=True, save_weights_only=False, mode='max', period=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:422: The name tf.global_variables is deprecated. Please use tf.compat.v1.global_variables instead.\n",
      "\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/callbacks/tensorboard_v1.py:200: The name tf.summary.merge_all is deprecated. Please use tf.compat.v1.summary.merge_all instead.\n",
      "\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/callbacks/tensorboard_v1.py:203: The name tf.summary.FileWriter is deprecated. Please use tf.compat.v1.summary.FileWriter instead.\n",
      "\n",
      "Epoch 1/30\n",
      "400/400 [==============================] - 468s 1s/step - loss: 0.1571 - categorical_accuracy: 0.9494 - val_loss: 0.0180 - val_categorical_accuracy: 0.9961\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/callbacks/tensorboard_v1.py:343: The name tf.Summary is deprecated. Please use tf.compat.v1.Summary instead.\n",
      "\n",
      "\n",
      "Epoch 00001: val_categorical_accuracy improved from -inf to 0.99609, saving model to logs/Recyclable-bs32-weights.01-0.996-DenseNet169.hdf5\n",
      "Epoch 2/30\n",
      "400/400 [==============================] - 436s 1s/step - loss: 0.0221 - categorical_accuracy: 0.9930 - val_loss: 3.3672e-04 - val_categorical_accuracy: 0.9968\n",
      "\n",
      "Epoch 00002: val_categorical_accuracy improved from 0.99609 to 0.99681, saving model to logs/Recyclable-bs32-weights.02-0.997-DenseNet169.hdf5\n",
      "Epoch 3/30\n",
      "400/400 [==============================] - 435s 1s/step - loss: 0.0160 - categorical_accuracy: 0.9956 - val_loss: 7.9943e-06 - val_categorical_accuracy: 0.9984\n",
      "\n",
      "Epoch 00003: val_categorical_accuracy improved from 0.99681 to 0.99840, saving model to logs/Recyclable-bs32-weights.03-0.998-DenseNet169.hdf5\n",
      "Epoch 4/30\n",
      "400/400 [==============================] - 432s 1s/step - loss: 0.0184 - categorical_accuracy: 0.9955 - val_loss: 2.0480e-04 - val_categorical_accuracy: 0.9976\n",
      "\n",
      "Epoch 00004: val_categorical_accuracy did not improve from 0.99840\n",
      "Epoch 5/30\n",
      "400/400 [==============================] - 432s 1s/step - loss: 0.0090 - categorical_accuracy: 0.9973 - val_loss: 6.0615e-05 - val_categorical_accuracy: 0.9976\n",
      "\n",
      "Epoch 00005: val_categorical_accuracy did not improve from 0.99840\n",
      "Epoch 6/30\n",
      "400/400 [==============================] - 433s 1s/step - loss: 0.0059 - categorical_accuracy: 0.9980 - val_loss: 7.1898e-07 - val_categorical_accuracy: 0.9992\n",
      "\n",
      "Epoch 00006: val_categorical_accuracy improved from 0.99840 to 0.99920, saving model to logs/Recyclable-bs32-weights.06-0.999-DenseNet169.hdf5\n",
      "Epoch 7/30\n",
      "400/400 [==============================] - 433s 1s/step - loss: 0.0055 - categorical_accuracy: 0.9985 - val_loss: 2.9243e-06 - val_categorical_accuracy: 0.9984\n",
      "\n",
      "Epoch 00007: val_categorical_accuracy did not improve from 0.99920\n",
      "Epoch 8/30\n",
      "400/400 [==============================] - 431s 1s/step - loss: 0.0033 - categorical_accuracy: 0.9989 - val_loss: 8.0466e-07 - val_categorical_accuracy: 1.0000\n",
      "\n",
      "Epoch 00008: val_categorical_accuracy improved from 0.99920 to 1.00000, saving model to logs/Recyclable-bs32-weights.08-1.000-DenseNet169.hdf5\n",
      "Epoch 9/30\n",
      "400/400 [==============================] - 430s 1s/step - loss: 0.0031 - categorical_accuracy: 0.9991 - val_loss: 5.5239e-05 - val_categorical_accuracy: 1.0000\n",
      "\n",
      "Epoch 00009: val_categorical_accuracy did not improve from 1.00000\n",
      "Epoch 10/30\n",
      "400/400 [==============================] - 432s 1s/step - loss: 0.0019 - categorical_accuracy: 0.9995 - val_loss: 0.0053 - val_categorical_accuracy: 1.0000\n",
      "\n",
      "Epoch 00010: val_categorical_accuracy did not improve from 1.00000\n",
      "Epoch 11/30\n",
      "400/400 [==============================] - 434s 1s/step - loss: 0.0031 - categorical_accuracy: 0.9992 - val_loss: 2.5450e-05 - val_categorical_accuracy: 1.0000\n",
      "\n",
      "Epoch 00011: val_categorical_accuracy did not improve from 1.00000\n",
      "Epoch 12/30\n",
      "400/400 [==============================] - 435s 1s/step - loss: 0.0029 - categorical_accuracy: 0.9991 - val_loss: 4.3586e-07 - val_categorical_accuracy: 1.0000\n",
      "\n",
      "Epoch 00012: val_categorical_accuracy did not improve from 1.00000\n",
      "Epoch 13/30\n",
      "400/400 [==============================] - 432s 1s/step - loss: 0.0016 - categorical_accuracy: 0.9997 - val_loss: 3.7366e-05 - val_categorical_accuracy: 1.0000\n",
      "\n",
      "Epoch 00013: val_categorical_accuracy did not improve from 1.00000\n",
      "Epoch 14/30\n",
      "400/400 [==============================] - 428s 1s/step - loss: 0.0017 - categorical_accuracy: 0.9996 - val_loss: 1.5534e-06 - val_categorical_accuracy: 1.0000\n",
      "\n",
      "Epoch 00014: val_categorical_accuracy did not improve from 1.00000\n",
      "Epoch 15/30\n",
      "168/400 [===========>..................] - ETA: 3:53 - loss: 0.0107 - categorical_accuracy: 0.9989"
     ]
    }
   ],
   "source": [
    "# Fit the model!\n",
    "model.fit_generator(trainGenerator,\n",
    "            steps_per_epoch = 400,  # trashnet 60\n",
    "            epochs = 30,\n",
    "            validation_data = validationGenerator,\n",
    "            validation_steps = 40,  \n",
    "            callbacks=[tensorboard, reduce_lr, checkpoint])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
